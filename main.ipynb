{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Tourism Experience Analytics - Data Preprocessing and Feature Engineering***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles:\n",
    " 1. Data loading and initial exploration\n",
    " 2. Data cleaning and standardization\n",
    " 3. Feature engineering\n",
    " 4. Final dataset preparation for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Loading and Initial Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Data loaded successfully!\n",
      "User data shape: (33530, 5)\n",
      "Attraction data shape: (17, 2)\n",
      "Visit data shape: (6, 2)\n",
      "Transaction data shape: (52930, 7)\n",
      "Region data shape: (22, 3)\n",
      "Item data shape: (30, 5)\n",
      "Country data shape: (165, 3)\n",
      "Continent data shape: (6, 2)\n",
      "City data shape: (9143, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "user_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\user_data.csv')\n",
    "attraction_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\attraction_type.csv')\n",
    "visit_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\visit_mode.csv')\n",
    "transaction_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\transaction_data.csv')\n",
    "region_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\region_data.csv')\n",
    "item_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\item_data.csv')\n",
    "country_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\country_data.csv')\n",
    "continent_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\continent_data.csv')\n",
    "city_data = pd.read_csv('D:\\\\Projects\\\\Guvi_Project4\\\\Datasets\\\\city_data.csv')\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(\"User data shape:\", user_data.shape)\n",
    "print(\"Attraction data shape:\", attraction_data.shape)   \n",
    "print(\"Visit data shape:\", visit_data.shape)\n",
    "print(\"Transaction data shape:\", transaction_data.shape)\n",
    "print(\"Region data shape:\", region_data.shape)\n",
    "print(\"Item data shape:\", item_data.shape)\n",
    "print(\"Country data shape:\", country_data.shape)\n",
    "print(\"Continent data shape:\", continent_data.shape)\n",
    "print(\"City data shape:\", city_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initial Data Quality Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== User Data Quality ===\n",
      "Shape: (33530, 5)\n",
      "\n",
      "Missing values:\n",
      "UserId         0\n",
      "ContinentId    0\n",
      "RegionId       0\n",
      "CountryId      0\n",
      "CityId         4\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64      4\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== City Data Quality ===\n",
      "Shape: (9143, 3)\n",
      "\n",
      "Missing values:\n",
      "CityId       0\n",
      "CityName     1\n",
      "CountryId    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64     2\n",
      "object    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Transaction Data Quality ===\n",
      "Shape: (52930, 7)\n",
      "\n",
      "Missing values:\n",
      "TransactionId    0\n",
      "UserId           0\n",
      "VisitYear        0\n",
      "VisitMonth       0\n",
      "VisitMode        0\n",
      "AttractionId     0\n",
      "Rating           0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64    7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rating stats:\n",
      "count    52930.000000\n",
      "mean         4.157699\n",
      "std          0.970543\n",
      "min          1.000000\n",
      "25%          4.000000\n",
      "50%          4.000000\n",
      "75%          5.000000\n",
      "max          5.000000\n",
      "Name: Rating, dtype: float64\n",
      "\n",
      "=== Visit Data Quality ===\n",
      "Shape: (6, 2)\n",
      "\n",
      "Missing values:\n",
      "VisitModeId    0\n",
      "VisitMode      0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64     1\n",
      "object    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Attraction Data Quality ===\n",
      "Shape: (17, 2)\n",
      "\n",
      "Missing values:\n",
      "AttractionTypeId    0\n",
      "AttractionType      0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64     1\n",
      "object    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_data_quality(df, name):\n",
    "    \"\"\"Helper function to check data quality metrics\"\"\"\n",
    "    print(f\"\\n=== {name} Data Quality ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    if 'Rating' in df.columns:\n",
    "        print(\"\\nRating stats:\")\n",
    "        print(df['Rating'].describe())\n",
    "    if 'VisitDate' in df.columns:\n",
    "        print(\"\\nDate range:\")\n",
    "        print(df['VisitDate'].min(), \"to\", df['VisitDate'].max())\n",
    "\n",
    "check_data_quality(user_data, \"User\")\n",
    "check_data_quality(city_data, \"City\")\n",
    "check_data_quality(transaction_data, \"Transaction\")\n",
    "check_data_quality(visit_data, \"Visit\")\n",
    "check_data_quality(attraction_data, \"Attraction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Cleaning and Standardization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Handling Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling missing values in user data...\n",
      "\n",
      "Handling missing values in city data...\n",
      "\n",
      "Cleaning rating values in transaction data...\n",
      "\n",
      "Removed 0 invalid ratings\n"
     ]
    }
   ],
   "source": [
    "# User data - drop rows with missing CityId (only 4 out of 33,530)\n",
    "print(\"\\nHandling missing values in user data...\")\n",
    "user_data.dropna(subset=['CityId'], inplace=True)\n",
    "\n",
    "# City data - drop rows with missing CityName\n",
    "print(\"\\nHandling missing values in city data...\")\n",
    "city_data.dropna(subset=['CityName'], inplace=True)\n",
    "\n",
    "# Transaction data - remove invalid ratings (1-5 scale)\n",
    "print(\"\\nCleaning rating values in transaction data...\")\n",
    "initial_count = len(transaction_data)\n",
    "transaction_data = transaction_data[transaction_data['Rating'].between(1, 5)]\n",
    "print(f\"\\nRemoved {initial_count - len(transaction_data)} invalid ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Standardizing Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardizing VisitMode...\n",
      "VisitMode values after standardization:\n",
      "VisitMode\n",
      "-           1\n",
      "Business    1\n",
      "Couples     1\n",
      "Family      1\n",
      "Friends     1\n",
      "Solo        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Standardizing AttractionType...\n",
      "AttractionType values after standardization:\n",
      "AttractionType\n",
      "Ancient Ruins                     1\n",
      "Ballets                           1\n",
      "Beaches                           1\n",
      "Caverns & Caves                   1\n",
      "Flea & Street Markets             1\n",
      "Historic Sites                    1\n",
      "History Museums                   1\n",
      "National Parks                    1\n",
      "Nature & Wildlife Areas           1\n",
      "Neighborhoods                     1\n",
      "Points Of Interest & Landmarks    1\n",
      "Religious Sites                   1\n",
      "Spas                              1\n",
      "Speciality Museums                1\n",
      "Volcanos                          1\n",
      "Water Parks                       1\n",
      "Waterfalls                        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Standardizing City Names...\n"
     ]
    }
   ],
   "source": [
    "# Standardize VisitMode\n",
    "print(\"\\nStandardizing VisitMode...\")\n",
    "visit_data['VisitMode'] = visit_data['VisitMode'].str.strip().str.title()\n",
    "print(\"VisitMode values after standardization:\")\n",
    "print(visit_data['VisitMode'].value_counts())\n",
    "\n",
    "# Standardize AttractionType\n",
    "print(\"\\nStandardizing AttractionType...\")\n",
    "attraction_data['AttractionType'] = attraction_data['AttractionType'].str.strip().str.title()\n",
    "print(\"AttractionType values after standardization:\")\n",
    "print(attraction_data['AttractionType'].value_counts())\n",
    "\n",
    "# Standardize City Names\n",
    "print(\"\\nStandardizing City Names...\")\n",
    "city_name_mapping = {\n",
    "    'New York City': 'New York', 'NYC': 'New York',\n",
    "    'San Fran': 'San Francisco', 'S.F.': 'San Francisco',\n",
    "    'Los Ang': 'Los Angeles', 'L.A.': 'Los Angeles',\n",
    "    'Chicago, Il': 'Chicago', 'Chi-Town': 'Chicago',\n",
    "    'Vegas': 'Las Vegas', 'D.C.': 'Washington DC',\n",
    "    'Wash D.C.': 'Washington DC', 'Philly': 'Philadelphia',\n",
    "    'Nola': 'New Orleans', 'Saint Louis': 'St. Louis',\n",
    "    'St Louis': 'St. Louis', 'Ft Worth': 'Fort Worth',\n",
    "    'Ft. Worth': 'Fort Worth', 'San Antone': 'San Antonio',\n",
    "    'Atl': 'Atlanta', 'H-Town': 'Houston',\n",
    "    'Big D': 'Dallas', 'Motor City': 'Detroit',\n",
    "    'Beantown': 'Boston', '-': None\n",
    "}\n",
    "\n",
    "city_data['CityName'] = (\n",
    "    city_data['CityName']\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    "    .replace(city_name_mapping)\n",
    "    .str.replace(r'\\bSt\\b\\.?', 'Saint', regex=True)\n",
    "    .str.replace(r'\\.', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Drop any remaining null city names\n",
    "city_data.dropna(subset=['CityName'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Standardizing Date Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardizing date format...\n",
      "Sample dates after standardization:\n",
      "   VisitYear  VisitMonth  VisitDate\n",
      "0       2022          10 2022-10-01\n",
      "1       2022          10 2022-10-01\n",
      "2       2022          10 2022-10-01\n",
      "3       2022          10 2022-10-01\n",
      "4       2022          10 2022-10-01\n"
     ]
    }
   ],
   "source": [
    "# Create proper date column in transaction data\n",
    "print(\"\\nStandardizing date format...\")\n",
    "transaction_data['VisitDate'] = pd.to_datetime(\n",
    "    transaction_data['VisitYear'].astype(str) + '-' + \n",
    "    transaction_data['VisitMonth'].astype(str) + '-01'\n",
    ")\n",
    "print(\"Sample dates after standardization:\")\n",
    "print(transaction_data[['VisitYear', 'VisitMonth', 'VisitDate']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Verifying Referential Integrity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking referential integrity...\n",
      "User IDs in transactions but not in user data: {17595, 56972, 67461, 7175}\n",
      "City IDs in user but not in city data: set()\n",
      "Attraction IDs in transactions but not in item data: set()\n",
      "Removed 4 orphaned transactions\n"
     ]
    }
   ],
   "source": [
    "# Check for orphaned records\n",
    "print(\"\\nChecking referential integrity...\")\n",
    "print(\"User IDs in transactions but not in user data:\", \n",
    "      set(transaction_data['UserId']) - set(user_data['UserId']))\n",
    "print(\"City IDs in user but not in city data:\", \n",
    "      set(user_data['CityId']) - set(city_data['CityId']))\n",
    "print(\"Attraction IDs in transactions but not in item data:\", \n",
    "      set(transaction_data['AttractionId']) - set(item_data['AttractionId']))\n",
    "\n",
    "# Remove orphaned transactions (users not in user_data)\n",
    "orphaned_users = {17595, 56972, 67461, 7175}\n",
    "transaction_data = transaction_data[~transaction_data['UserId'].isin(orphaned_users)]\n",
    "print(f\"Removed {len(orphaned_users)} orphaned transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Encoding Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical variables...\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode VisitMode\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "visit_encoded = pd.get_dummies(visit_data, columns=['VisitMode'], prefix='VisitMode')\n",
    "\n",
    "# Frequency encoding for Country\n",
    "country_counts = user_data['CountryId'].value_counts(normalize=True)\n",
    "user_data['Country_freq_encoded'] = user_data['CountryId'].map(country_counts)\n",
    "\n",
    "# One-hot encode AttractionType\n",
    "attraction_encoded = pd.get_dummies(attraction_data, columns=['AttractionType'], prefix='Attraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Data Consolidation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerging datasets...\")\n",
    "# Merge transaction with user data\n",
    "merged_df = pd.merge(transaction_data, user_data, on='UserId')\n",
    "\n",
    "# Merge with city data\n",
    "merged_df = pd.merge(merged_df, city_data, left_on='CityId', right_on='CityId', suffixes=('_user', '_city'))\n",
    "\n",
    "# Merge with item and attraction data\n",
    "merged_df = pd.merge(merged_df, item_data, on='AttractionId')\n",
    "merged_df = pd.merge(merged_df, attraction_data, on='AttractionTypeId')\n",
    "\n",
    "# Merge with visit mode data\n",
    "merged_df = pd.merge(merged_df, visit_data, left_on='VisitMode', right_on='VisitModeId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Creating User-Level Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating user-level features...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating user-level features...\")\n",
    "# Calculate user-level statistics\n",
    "user_features = merged_df.groupby('UserId').agg({\n",
    "    'Rating': ['mean', 'count', 'std'],\n",
    "    'VisitMode_y': lambda x: x.mode()[0],\n",
    "    'AttractionId': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-index columns\n",
    "user_features.columns = ['UserId', 'AvgRating', 'TotalVisits', 'RatingStd', 'FrequentVisitMode', 'UniqueAttractions']\n",
    "\n",
    "# Calculate visit mode proportions\n",
    "visit_mode_counts = merged_df.groupby(['UserId', 'VisitMode_y']).size().unstack(fill_value=0)\n",
    "visit_mode_proportions = visit_mode_counts.div(visit_mode_counts.sum(axis=1), axis=0)\n",
    "visit_mode_proportions = visit_mode_proportions.add_prefix('VisitModeProp_')\n",
    "\n",
    "# Combine with main dataframe\n",
    "merged_df = pd.merge(merged_df, user_features, on='UserId')\n",
    "merged_df = pd.merge(merged_df, visit_mode_proportions, left_on='UserId', right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4 Final Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final feature engineering...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal feature engineering...\")\n",
    "# One-hot encoding\n",
    "merged_df = pd.get_dummies(merged_df, columns=[\n",
    "    'VisitMode_y', 'AttractionType', 'ContinentId'\n",
    "], drop_first=True)\n",
    "\n",
    "# Temporal features\n",
    "merged_df['VisitYear'] = merged_df['VisitDate'].dt.year\n",
    "merged_df['VisitMonth'] = merged_df['VisitDate'].dt.month\n",
    "merged_df['VisitDayOfWeek'] = merged_df['VisitDate'].dt.dayofweek\n",
    "merged_df['IsWeekend'] = merged_df['VisitDayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numerical_features = ['Rating', 'AvgRating', 'TotalVisits', 'UniqueAttractions']\n",
    "scaler = MinMaxScaler()\n",
    "merged_df[numerical_features] = scaler.fit_transform(merged_df[numerical_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Final Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting final features...\n",
      "\n",
      "Handling missing values in final dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2724\\781340121.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  modeling_df[numerical_cols] = modeling_df[numerical_cols].fillna(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2724\\781340121.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  modeling_df[visit_mode_cols] = modeling_df[visit_mode_cols].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2724\\781340121.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  modeling_df['Rating'] = modeling_df['Rating'].fillna(modeling_df['Rating'].median())\n"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "print(\"\\nSelecting final features...\")\n",
    "selected_features = [\n",
    "    # User features\n",
    "    'AvgRating', 'TotalVisits', 'RatingStd', 'UniqueAttractions',\n",
    "    \n",
    "    # Visit behavior\n",
    "    *[col for col in merged_df.columns if col.startswith('VisitModeProp_')],\n",
    "    *[col for col in merged_df.columns if col.startswith('VisitMode_y_')],\n",
    "    \n",
    "    # Attraction features\n",
    "    *[col for col in merged_df.columns if col.startswith('AttractionType_')],\n",
    "    \n",
    "    # Location features\n",
    "    *[col for col in merged_df.columns if col.startswith('ContinentId_')],\n",
    "    'Country_freq_encoded',\n",
    "    \n",
    "    # Temporal features\n",
    "    'VisitYear', 'VisitMonth', 'IsWeekend'\n",
    "]\n",
    "\n",
    "modeling_df = merged_df[selected_features + ['Rating']]\n",
    "\n",
    "# Handle any remaining missing values\n",
    "print(\"\\nHandling missing values in final dataset...\")\n",
    "numerical_cols = ['AvgRating', 'TotalVisits', 'RatingStd']\n",
    "modeling_df[numerical_cols] = modeling_df[numerical_cols].fillna(\n",
    "    modeling_df[numerical_cols].median()\n",
    ")\n",
    "\n",
    "visit_mode_cols = [col for col in modeling_df.columns if 'VisitModeProp_' in col]\n",
    "modeling_df[visit_mode_cols] = modeling_df[visit_mode_cols].fillna(0)\n",
    "\n",
    "modeling_df['Rating'] = modeling_df['Rating'].fillna(modeling_df['Rating'].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Dataset Summary ===\n",
      "Shape: (52922, 38)\n",
      "\n",
      "First 5 columns and last 5 columns:\n",
      "['AvgRating', 'TotalVisits', 'RatingStd', 'UniqueAttractions', 'VisitModeProp_Business'] ... ['Country_freq_encoded', 'VisitYear', 'VisitMonth', 'IsWeekend', 'Rating']\n",
      "\n",
      "Data types:\n",
      "bool       24\n",
      "float64    11\n",
      "int32       2\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values: 0\n",
      "\n",
      "Normalized features range check:\n",
      "     Rating  AvgRating  TotalVisits  UniqueAttractions\n",
      "min     0.0        0.0          0.0                0.0\n",
      "max     1.0        1.0          1.0                1.0\n",
      "\n",
      "Saving final dataset...\n",
      "Preprocessing complete! Final dataset saved as 'preprocessed_tourism_data.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Dataset Summary ===\")\n",
    "print(\"Shape:\", modeling_df.shape)\n",
    "print(\"\\nFirst 5 columns and last 5 columns:\")\n",
    "print(modeling_df.columns[:5].tolist(), \"...\", modeling_df.columns[-5:].tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(modeling_df.dtypes.value_counts())\n",
    "print(\"\\nMissing values:\", modeling_df.isna().sum().sum())\n",
    "print(\"\\nNormalized features range check:\")\n",
    "print(modeling_df[numerical_features].describe().loc[['min', 'max']])\n",
    "\n",
    "# Save final dataset\n",
    "print(\"\\nSaving final dataset...\")\n",
    "modeling_df.to_csv('preprocessed_tourism_data.csv', index=False)\n",
    "print(\"Preprocessing complete! Final dataset saved as 'preprocessed_tourism_data.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
